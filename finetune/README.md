### DeepSeek-V3 671B LoRA finetuning code

Edit the LoRA configuration in `model_utils.py` and run `finetune_model.py` to finetune DeepSeek in a tensor-parallel way. Requires 16 H100s at minimum. Improved docs on the way.
